---
title: "Viral integration simulations - pilot experiment"
output:
  html_notebook:
    code_folding: hide
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---
```{r setup, include=FALSE}
library(tidyverse)
library(kableExtra)
source("sim_functions.R")

easier_sim <- "../out/test/test-easier/simulation_summary.tsv"
easier_analy <- "../out/test/test-easier/analysis_conditions.tsv"
easier_results <- "../out/test/test-easier/test-easier.scored_reads_summary.tsv"

harder_sim <- "../out/test/test-harder/simulation_summary.tsv"
harder_analy <- "../out/test/test-harder/analysis_conditions.tsv"
harder_results <- "../out/test/test-harder/test-harder.scored_reads_summary.tsv"
harder_ints <- "../out/test/test-harder/sim_ints/cond0.rep0.int-info.annotated.tsv"

```



```{css, echo=FALSE}
.scroll-100 {
  max-height: 300px;
  overflow-y: auto;
  background-color: inherit;
}
```


## Overview
The first experiment I did was to test out the simulation pipeline, and try to analyse the data, and compare the results from analysis with what would be expected from the pipeline.  

## Data
The only data required for simulation experiments are host and virus references.  

For the host, I used chr2:100000:102999 and chr3:100000:102999 from hg38.   

For the virus I used rep68 from AAV2 (NC_001401.2_cds_YP_680422.1_1, protein_id=YP_680422.1, db_xref=GeneID:4192013)

## Simulation parameters

I simulated two different situations using this data: one that I thought would be 'easier' for the pipeline to handle, and one that is 'harder'.

The parameters used for each were:
```{bash class.output="scroll-100"}
cat "../config/test/sim_and_detect.yml"

```

In the 'easier' condition, there are five integrations of the whole virus, with clean junctions and no rearrangements, deletions of the virus, and no host deletions either.  In the 'harder' condition the host and virus reference are the same, but there's a high probability of rearrangements, deletions, gaps and overlaps at the junctions, and host deletions.  There are also some 'episomal' sequences included in the output fasta.

The DAG from snakemake looks like this:
![DAG for this experiment](../out/test/test_combined.dag.svg)

## Results

There are a few different ways of scoring the results from these experiments.  One thing to look at is just simply if all the reads that cross integrations in the simulated fasta are found in the output.  Within those reads that are found, we can also look at if the locations of the integration in the host and vector genomes are correct.

### Are all the reads that cross integrations found?

```{r include=FALSE}
easier <- importData(easier_sim, easier_analy, easier_results)
harder <- importData(harder_sim, harder_analy, harder_results)
results <- bind_rows(easier, harder)
```

Firstly, check each read in the simulation and compare the expected output with the actual output.  The reads were scored as follows:

|  | True positive | True negative | False positive | False negative |
|:-:|:-:|:-:|:-:|:-:|
| Cross simulated integration junction? | Yes | No | No | Yes |
| Found in analysis pipeline output? | Yes | No | Yes | No |

The events of most concern are the false positives.

In the 'easier' condition, reads were either merged (using seq-prep) or not during analysis.  In the 'harder' condition, reads were always merged.  

Each read was considered to be a potential chimeric read, and additionally each pair was considered to be a posisble discordant read pair.  The chimeric reads and discordant pairs were scored separately.


```{r}
results %>% 
  filter(!post) %>%
  filter(score_type == 'found_score') %>% 
  select(experiment, merge, junc_type, true_positive, true_negative, false_positive, false_negative) %>% 
  mutate(merge = ifelse(merge ==1, TRUE, FALSE))   %>% 
  kable() %>%
  kable_styling()
  
```

So we have some false negatives for the 'harder' condition, but the 'easier' condition is perfect.

#### False negatives - missing reads

Check out if the reads missed in the 'test-harder' condition come from particular integrations:
```{bash, engine.opts='-e'}
echo "int_id  type"
awk 'match($3, /fn/)' "../out/test/test-harder/scored_reads/test-harder_analysis0.cond0.rep0.human.AAV.tsv" | cut -f2,10 | sort | uniq
```


So all the missing integrations come from two (of five) integrations - with ids '3' and '4'.  For context, the properties of all the integrations were:
```{r}
read_tsv(harder_ints)
```

These two integrations are of rearranged virus fragments.  The most obvious difference between these two integrations and the other integrations is that they have some pieces that are particularly short (relative to the 150pb reads) - integration 4 has a second fragment which is `r 1545-1487`bp long, and integration 3 has a second fragment which is `r 476-423`bp long.  It's possible that a read could start in the first rearranged piece, and extend through the second rearranged piece into the host.  This hypothetical read would be mapped either to the first reaarranged piece (and have a lot more soft-clipped reads than it should), or to the second rearranged piece (and be soft-clipped on each end of the read).  

Check the CIGAR strings of these reads that were missed - first the chimeric reads:
```{bash, engine.opts='-l', class.output="scroll-100"}
conda activate simvi

LIST=$(awk 'match($3, /fn/) && match($9, /chimeric/)' "../out/test/test-harder/scored_reads/test-harder_analysis0.cond0.rep0.human.AAV.tsv" | cut -f1 | sort | uniq)

for l in $LIST; do
  echo "viral alignment:"
  python3 python_scripts/print_cigars_from_sam.py ../out/test/test-harder_analysis0_human_AAV/virus_aligned/cond0.rep0.AAV.sam  $l
  echo "host_alignment:"
  python3 python_scripts/print_cigars_from_sam.py ../out/test/test-harder_analysis0_human_AAV/host_aligned/cond0.rep0.human.readsFromAAV.sam $l  
  echo 
  
done
```

For these reads, it makes sense that they're missed (eg chr2-114/1) - because one of the reads (the viral read) is clipped on both ends.  

What about the discordant read pairs?

```{bash, engine.opts='-l', class.output="scroll-100"}
conda activate simvi

LIST=$(awk 'match($3, /fn/) && match($9, /discord/)' "../out/test/test-harder/scored_reads/test-harder_analysis0.cond0.rep0.human.AAV.tsv" | cut -f1 | sort | uniq)

for l in $LIST; do
  echo "viral alignment:"
  python3 python_scripts/print_cigars_from_sam.py ../out/test/test-harder_analysis0_human_AAV/virus_aligned/cond0.rep0.AAV.sam  $l
  echo "host_alignment:"
  python3 python_scripts/print_cigars_from_sam.py ../out/test/test-harder_analysis0_human_AAV/host_aligned/cond0.rep0.human.readsFromAAV.sam $l  
  echo 
  
done
```

In the viral reads there are now too many bases clipped for the read to be considered 'mapped', so these pairs aren't found.

### Are the integrations in the right locations?

We can also check if the integrations are in the correct locations in the host and vector references.  To check this, score the reads in the same way as before, except that a read is only a true positve if it crosses a location, is found in the analysis output AND the output location in the analysis is correct. 

A read is defined to be in the 'correct' location if:  
 - the chromosome or virus is correctly identified
 - the start and stop positions of the integration from the simulation overlap with those in the analysis results
   - when checking for overlap, we allow a small amount of 'wiggle room' - a small number of bases are subtracted from the start and added to the stop coordates in the analysis output.  In this case, this number was 5
 - for chimeric reads only, we check that the start and stop coordinates are within a set number of bases from their counterparts in the analysis results.  That is, the start in the analysis results and the start coordinate of the simulated integration must be within a certain number of bases of each other, and same for the stop coordinates.  In this case, this nubmer was 5.  This isn't possible to check for discordant read pairs because the integration coordinates cannot be accurately determined during analysis.

#### Host
When we check the location the host, the scores are the following:
```{r}
results %>% 
  filter(!post) %>%
  filter(score_type == 'host_score') %>% 
  select(experiment, merge, junc_type, true_positive, true_negative, false_positive, false_negative) %>% 
  mutate(merge = ifelse(merge ==1, TRUE, FALSE))   %>% 
  kable() %>%
  kable_styling()
```

So all of the reads that were output as integrations have the correct location within the host (because this table is identical to the one above).  The reads that were scored as 'false negatives' above, by definition must be false negatives when also checking for correct host location.

#### Virus
And for the location in the virus:
```{r}
results %>% 
  filter(!post) %>%
  filter(score_type == 'virus_score') %>% 
  select(experiment, merge, junc_type, true_positive, true_negative, false_positive, false_negative) %>% 
  mutate(merge = ifelse(merge ==1, TRUE, FALSE))   %>% 
  kable() %>%
  kable_styling()
```


So it looks like in the 'harder' condition, we have a few reads that have an incorrect position within the virus.  Check if these reads come from a particular integration, which perhaps some particularly difficult properties.  

Check out the reads that were true positives based on 

Print out the properties of the simulated integrations

```{bash, engine.opts='-e'}
LIST=$(awk 'match($5,/fn/) && match($3, /tp/) && match($10,/discord/)' "../out/test/test-harder/scored_reads/test-harder_analysis0.cond0.rep0.human.AAV.tsv" | cut -f2 | sort | uniq)

for l in $LIST; do
  awk "\$1 ~ /$l/" ../out/test/test-harder/sim_ints/cond0.rep0.int-info.tsv
done

```


## Session info
```{r}
sessionInfo()
```

